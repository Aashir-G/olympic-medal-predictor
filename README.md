# ğŸ¥‡ Olympic Medal Predictor

A machine learning project that predicts how many medals a country will win at the Olympics based on historical participation and performance.
The system uses past Olympic data to engineer country-level features such as number of athletes and medals from the previous Games, then trains a regression model to estimate medal counts. The entire pipeline is automated, reproducible, and version-controlled, from raw data ingestion to a CLI prediction tool.

This is not just a notebook project. It is a complete ML pipeline with data processing, model training, evaluation, and deployment-style inference.

---

## ğŸš€ Tech Stack

* **Python**
* **Pandas, NumPy** â€“ data cleaning & feature engineering
* **scikit-learn** â€“ model training (Ridge Regression)
* **Matplotlib** â€“ visualization
* **Joblib** â€“ model serialization
* **Jupyter Notebook** â€“ EDA
* **Git & GitHub** â€“ version control
* **VS Code** â€“ development environment

---

## ğŸ“‚ Dataset

Dataset:
**120 years of Olympic history: athletes and results** (Kaggle â€“ heesoo37)

Raw files are not committed to Git. They are downloaded locally using KaggleHub.

Expected files:

```
data/raw/athlete_events.csv
data/raw/noc_regions.csv
```

Download:

```bash
pip install kagglehub
python download_dataset.py
```

---

## âš™ï¸ How to Run

From the project root:

1. Create clean dataset:

```bash
python -m src.make_dataset
```

2. Train the model:

```bash
python -m src.train --test_year 2016
```

3. Evaluate performance:

```bash
python -m src.evaluate
```

4. Make a prediction (CLI tool):

```bash
python -m src.predict --country "Canada" --athletes 315 --prev_medals 24
```

---

## ğŸ“Š Results

Model performance is evaluated using **Mean Absolute Error (MAE)** on a time-based holdout year.

Example:

```
Test Year: 2016  
MAE: ~X.XX medals
```

This means that on average, predictions are within about **X medals** of the real outcome per country.

![alt text](image.png)
![alt text](image-1.png)

---

## ğŸ—‚ Project Structure

```
olympic-medal-predictor/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/            # Raw datasets (ignored by Git)
â”‚   â””â”€â”€ processed/      # Clean dataset generated by pipeline
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 01_eda.ipynb    # Exploratory data analysis
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py       # Centralized paths
â”‚   â”œâ”€â”€ make_dataset.py# Data processing pipeline
â”‚   â”œâ”€â”€ train.py        # Model training
â”‚   â”œâ”€â”€ evaluate.py     # Evaluation + MAE
â”‚   â””â”€â”€ predict.py      # CLI prediction tool
â”‚
â”œâ”€â”€ models/             # Saved models (ignored by Git)
â”œâ”€â”€ download_dataset.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ”® Future Improvements

* Add more features:

  * GDP, population, host country advantage
  * Sports-specific performance trends

* Try stronger models:

  * Random Forest
  * Gradient Boosting (XGBoost/LightGBM)

* Hyperparameter tuning with cross-validation

* Turn the CLI into:

  * A small web app (Flask / FastAPI)
  * Or a dashboard

* Add experiment tracking (MLflow)


